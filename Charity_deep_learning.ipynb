{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabroo101/deep-learning-challenge/blob/main/Charity_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-lMMRIx2P_l"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsD3PGba2P_p"
      },
      "source": [
        "---\n",
        "\n",
        "# **Charity Deep Learning Project**\n",
        "\n",
        "In this project, we'll be exploring deep learning techniques to understand and make predictions related to charity data.\n",
        "\n",
        "## **Step 1: Importing Dependencies**\n",
        "\n",
        "Before we dive into the actual data analysis, let's import all the necessary libraries and modules:\n",
        "\n",
        "```python\n",
        "# Data manipulation and splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Deep learning library\n",
        "import tensorflow as tf\n",
        "```\n",
        "\n",
        "## **Step 2: Loading the Data**\n",
        "\n",
        "We'll be using a dataset named `charity_data.csv` which contains relevant information about different charities. Let's load this data and take a quick look at the first few rows:\n",
        "\n",
        "```python\n",
        "# Import the dataset\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "application_df.head()\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnwtp4e2P_q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Alphabet Soup's Dataset Information\n",
        "\n",
        "From Alphabet Soupâ€™s business team, we have obtained a comprehensive CSV dataset. This dataset encompasses data from over 34,000 organizations that have been beneficiaries of funding from Alphabet Soup throughout the years.\n",
        "\n",
        "## Columns Description:\n",
        "\n",
        "The dataset provides a range of columns, capturing metadata about each organization:\n",
        "\n",
        "- **EIN and NAME**: Identification columns.\n",
        "  \n",
        "- **APPLICATION_TYPE**: Describes the Alphabet Soup application type.\n",
        "\n",
        "- **AFFILIATION**: Represents the affiliated sector of the industry.\n",
        "\n",
        "- **CLASSIFICATION**: Refers to the government organization classification.\n",
        "\n",
        "- **USE_CASE**: Specifies the use case for which the funding is granted.\n",
        "\n",
        "- **ORGANIZATION**: Type of the organization.\n",
        "\n",
        "- **STATUS**: Indicates whether the organization is currently active or not.\n",
        "\n",
        "- **INCOME_AMT**: Categorizes organizations based on their income.\n",
        "\n",
        "- **SPECIAL_CONSIDERATIONS**: Notes if there are any special considerations for the application.\n",
        "\n",
        "- **ASK_AMT**: The amount of funding the organization requested.\n",
        "\n",
        "- **IS_SUCCESSFUL**: Determines whether the funding was utilized effectively.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZBzuWzwS2P_r",
        "outputId": "40cd6506-9cf0-4164-9cd4-748e255948bb"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   EIN                     34299 non-null  int64 \n",
            " 1   NAME                    34299 non-null  object\n",
            " 2   APPLICATION_TYPE        34299 non-null  object\n",
            " 3   AFFILIATION             34299 non-null  object\n",
            " 4   CLASSIFICATION          34299 non-null  object\n",
            " 5   USE_CASE                34299 non-null  object\n",
            " 6   ORGANIZATION            34299 non-null  object\n",
            " 7   STATUS                  34299 non-null  int64 \n",
            " 8   INCOME_AMT              34299 non-null  object\n",
            " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
            " 10  ASK_AMT                 34299 non-null  int64 \n",
            " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
            "dtypes: int64(4), object(8)\n",
            "memory usage: 3.1+ MB\n",
            "None\n"
          ]
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "print(application_df.info())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UR9R4fE2P_t"
      },
      "source": [
        "\n",
        "\n",
        "## Data Cleaning\n",
        "\n",
        "### Dropping Non-Beneficial Columns\n",
        "\n",
        "For our analysis, certain columns such as 'EIN' and 'NAME' are not beneficial. These columns serve as identification for the organizations but do not offer any substantive information for our machine learning model. Therefore, we'll drop these columns from our dataset:\n",
        "\n",
        "```python\n",
        "application_df.drop(columns=[\"EIN\", \"NAME\"], inplace=True)\n",
        "```\n",
        "\n",
        "**Note**: It's essential to include the `inplace=True` parameter if you wish to modify the `application_df` directly. Without it, the changes won't be saved to the `application_df` but will return a new DataFrame with the columns dropped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6w_BmF_2P_t",
        "outputId": "3a3f7ba9-d091-431c-83ce-b8c58b15ee0f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(columns=[\"EIN\" , \"NAME\"] , inplace= True)\n",
        "\n",
        "#check data\n",
        "application_df.head()\n",
        "\n",
        "#check target: to see if there are any bug difrenceses in value count\n",
        "application_df[\"IS_SUCCESSFUL\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYwF8l232P_u"
      },
      "source": [
        "\n",
        "## Unique Value Analysis\n",
        "\n",
        "To understand the diversity of our dataset and to ascertain potential candidates for one-hot encoding (among other preprocessing steps), we first determine the number of unique values in each column:\n",
        "\n",
        "```python\n",
        "application_df.nunique()\n",
        "```\n",
        "\n",
        "By examining the unique count, we can get insights into the categorical nature of our data and decide on the next preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "application_df.dtypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFE2tUAr7F2W",
        "outputId": "30dc72c8-4569-4164-e54c-48e675fb2ee6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE          object\n",
              "AFFILIATION               object\n",
              "CLASSIFICATION            object\n",
              "USE_CASE                  object\n",
              "ORGANIZATION              object\n",
              "STATUS                     int64\n",
              "INCOME_AMT                object\n",
              "SPECIAL_CONSIDERATIONS    object\n",
              "ASK_AMT                    int64\n",
              "IS_SUCCESSFUL              int64\n",
              "dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "zPPtXa_t2P_u",
        "outputId": "0eb82d32-8a7d-4255-d7a2-0a5465c57517",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "APPLICATION_TYPE            17\n",
              "AFFILIATION                  6\n",
              "CLASSIFICATION              71\n",
              "USE_CASE                     5\n",
              "ORGANIZATION                 4\n",
              "STATUS                       2\n",
              "INCOME_AMT                   9\n",
              "SPECIAL_CONSIDERATIONS       2\n",
              "ASK_AMT                   8747\n",
              "IS_SUCCESSFUL                2\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df_count = application_df.nunique()\n",
        "application_df_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "uD-H0gDU2P_v",
        "outputId": "18d4484b-2c4c-4195-e832-ae0c3c75b30f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_type_count =  application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_type_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1R8MlO2P_v"
      },
      "source": [
        "\n",
        "\n",
        "1. **Choosing a Cutoff**:\n",
        "    ```python\n",
        "    application_types_to_replace = application_type_count[8:].index\n",
        "    ```\n",
        "   Here, the code selects a cutoff based on the index. The `[8:]` slice means you're taking all application types from the 8th index onward. This assumes that `application_type_count` is already sorted in descending order by count. The code is effectively saying, \"Let's replace all application types from the 8th least frequent type and beyond.\"\n",
        "\n",
        "2. **Replacement**:\n",
        "    ```python\n",
        "    for app in application_types_to_replace:\n",
        "        application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "    ```\n",
        "    This loop replaces all the application types in the `application_types_to_replace` list with the label \"Other\" in the DataFrame `application_df`.\n",
        "\n",
        "3. **Checking**:\n",
        "    ```python\n",
        "    application_df['APPLICATION_TYPE'].value_counts()\n",
        "    ```\n",
        "    This line checks and displays the updated counts for each `APPLICATION_TYPE`, verifying that the replacement was successful.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR2D4vPN2P_w"
      },
      "source": [
        "---\n",
        "\n",
        "### Explanation\n",
        "\n",
        "---\n",
        "\n",
        "## **Minimizing Application Types**\n",
        "\n",
        "In our dataset, there are multiple `APPLICATION_TYPE`s, some of which occur very infrequently. Having many infrequent categories can sometimes introduce noise into our machine learning models, making them less effective. By reducing the number of infrequent categories, we aim to create a more generalizable model.\n",
        "\n",
        "### **Procedure**:\n",
        "\n",
        "1. **Determine Cutoff**:\n",
        "   \n",
        "   We choose a cutoff to determine which application types are considered \"infrequent.\" For our current approach, we select all application types from the 8th least frequent type onward. These types will be replaced with a more general label: \"Other.\"\n",
        "\n",
        "    ```python\n",
        "    application_types_to_replace = application_type_count[8:].index\n",
        "    ```\n",
        "\n",
        "2. **Replacement**:\n",
        "   \n",
        "   Next, we iterate over the identified application types and replace them in our dataset.\n",
        "\n",
        "    ```python\n",
        "    for app in application_types_to_replace:\n",
        "        application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "    ```\n",
        "\n",
        "3. **Validation**:\n",
        "   \n",
        "   Finally, to ensure our changes have taken effect, we check the updated value counts for `APPLICATION_TYPE`.\n",
        "\n",
        "    ```python\n",
        "    application_df['APPLICATION_TYPE'].value_counts()\n",
        "    ```\n",
        "\n",
        "### **Rationale**:\n",
        "\n",
        "Minimizing the number of categories in our dataset can:\n",
        "\n",
        "- **Enhance Model Generalization**: By reducing sparse categories, we reduce the chance of overfitting to specific categories that don't have enough representation.\n",
        "  \n",
        "- **Streamline Encoding**: Later, when we encode these categories for modeling, fewer categories can lead to fewer columns, making our dataset more manageable and the model faster.\n",
        "\n",
        "- **Improve Interpretability**: Models become more interpretable with fewer categories as the focus shifts to more significant, broad categories rather than nuanced, infrequent ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6hregHut2P_w",
        "outputId": "86854426-98b4-4070-ce7f-89b8cb2c08b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = [application_type_count[application_type_count.values < 500].index]\n",
        "application_types_to_replace\n",
        "#review video\n",
        "\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "# application_types_to_replace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "2nPm9jq92P_w",
        "outputId": "f3f53773-7e7a-4e27-ad5f-451d370253ea",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "C2800       95\n",
              "C7100       75\n",
              "C1300       58\n",
              "C1280       50\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_count = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "classification_count.head(15)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classification_to_replace = classification_count[classification_count.values <  ]"
      ],
      "metadata": {
        "id": "RB2PrfiK8z7b",
        "outputId": "fadd1161-6aa0-4b23-f180-fb2093b7b537",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-08dd158b57e5>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mclassi\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'classi' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jUQduTUx870V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZsZCd-BB2P_w"
      },
      "outputs": [],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n",
        "#  YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "replace"
      ],
      "metadata": {
        "id": "0gXGButH9TGc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PazBY-B32P_x"
      },
      "outputs": [],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "replace\n",
        "# Replace in dataframe\n",
        "for cls in classifications_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1soqfm0k2P_x"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "#  YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4JhHMx_Q2P_x"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df[\"IS_SUCCESSFUL\"]\n",
        "X = application_df.drop(columns=\"IS_SUCCESSFUL\")\n",
        "X.SHAPE\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "#  YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7yNViUGL2P_x"
      },
      "outputs": [],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-vXXQAP2P_x"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4EDgdxa02P_y"
      },
      "outputs": [],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# Second hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# Output layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qw4VfwAk2P_y"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "#  YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sXqvqJQS2P_y"
      },
      "outputs": [],
      "source": [
        "# Train the model\n",
        "#  YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A5fmFwh22P_y"
      },
      "outputs": [],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0G9V__Vq2P_y"
      },
      "outputs": [],
      "source": [
        "# Export our model to HDF5 file\n",
        "#  YOUR CODE GOES HERE"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}