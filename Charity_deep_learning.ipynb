{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nabroo101/deep-learning-challenge/blob/main/Charity_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F-lMMRIx2P_l"
      },
      "source": [
        "## Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IsD3PGba2P_p"
      },
      "source": [
        "---\n",
        "\n",
        "# **Charity Deep Learning Project**\n",
        "\n",
        "In this project, we'll be exploring deep learning techniques to understand and make predictions related to charity data.\n",
        "\n",
        "## **Step 1: Importing Dependencies**\n",
        "\n",
        "Before we dive into the actual data analysis, let's import all the necessary libraries and modules:\n",
        "\n",
        "```python\n",
        "# Data manipulation and splitting\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "import pandas as pd\n",
        "\n",
        "# Deep learning library\n",
        "import tensorflow as tf\n",
        "```\n",
        "\n",
        "## **Step 2: Loading the Data**\n",
        "\n",
        "We'll be using a dataset named `charity_data.csv` which contains relevant information about different charities. Let's load this data and take a quick look at the first few rows:\n",
        "\n",
        "```python\n",
        "# Import the dataset\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "\n",
        "# Display the first few rows of the dataset\n",
        "application_df.head()\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CRnwtp4e2P_q"
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "# Alphabet Soup's Dataset Information\n",
        "\n",
        "From Alphabet Soupâ€™s business team, we have obtained a comprehensive CSV dataset. This dataset encompasses data from over 34,000 organizations that have been beneficiaries of funding from Alphabet Soup throughout the years.\n",
        "\n",
        "## Columns Description:\n",
        "\n",
        "The dataset provides a range of columns, capturing metadata about each organization:\n",
        "\n",
        "- **EIN and NAME**: Identification columns.\n",
        "  \n",
        "- **APPLICATION_TYPE**: Describes the Alphabet Soup application type.\n",
        "\n",
        "- **AFFILIATION**: Represents the affiliated sector of the industry.\n",
        "\n",
        "- **CLASSIFICATION**: Refers to the government organization classification.\n",
        "\n",
        "- **USE_CASE**: Specifies the use case for which the funding is granted.\n",
        "\n",
        "- **ORGANIZATION**: Type of the organization.\n",
        "\n",
        "- **STATUS**: Indicates whether the organization is currently active or not.\n",
        "\n",
        "- **INCOME_AMT**: Categorizes organizations based on their income.\n",
        "\n",
        "- **SPECIAL_CONSIDERATIONS**: Notes if there are any special considerations for the application.\n",
        "\n",
        "- **ASK_AMT**: The amount of funding the organization requested.\n",
        "\n",
        "- **IS_SUCCESSFUL**: Determines whether the funding was utilized effectively.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 865
        },
        "id": "ZBzuWzwS2P_r",
        "outputId": "38cb4593-c6ce-4841-a1fe-a95cb0a5fce6"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-08-16 19:26:33.278069: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
            "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 34299 entries, 0 to 34298\n",
            "Data columns (total 12 columns):\n",
            " #   Column                  Non-Null Count  Dtype \n",
            "---  ------                  --------------  ----- \n",
            " 0   EIN                     34299 non-null  int64 \n",
            " 1   NAME                    34299 non-null  object\n",
            " 2   APPLICATION_TYPE        34299 non-null  object\n",
            " 3   AFFILIATION             34299 non-null  object\n",
            " 4   CLASSIFICATION          34299 non-null  object\n",
            " 5   USE_CASE                34299 non-null  object\n",
            " 6   ORGANIZATION            34299 non-null  object\n",
            " 7   STATUS                  34299 non-null  int64 \n",
            " 8   INCOME_AMT              34299 non-null  object\n",
            " 9   SPECIAL_CONSIDERATIONS  34299 non-null  object\n",
            " 10  ASK_AMT                 34299 non-null  int64 \n",
            " 11  IS_SUCCESSFUL           34299 non-null  int64 \n",
            "dtypes: int64(4), object(8)\n",
            "memory usage: 3.1+ MB\n",
            "None\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>EIN</th>\n",
              "      <th>NAME</th>\n",
              "      <th>APPLICATION_TYPE</th>\n",
              "      <th>AFFILIATION</th>\n",
              "      <th>CLASSIFICATION</th>\n",
              "      <th>USE_CASE</th>\n",
              "      <th>ORGANIZATION</th>\n",
              "      <th>STATUS</th>\n",
              "      <th>INCOME_AMT</th>\n",
              "      <th>SPECIAL_CONSIDERATIONS</th>\n",
              "      <th>ASK_AMT</th>\n",
              "      <th>IS_SUCCESSFUL</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>10520599</td>\n",
              "      <td>BLUE KNIGHTS MOTORCYCLE CLUB</td>\n",
              "      <td>T10</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>10531628</td>\n",
              "      <td>AMERICAN CHESAPEAKE CLUB CHARITABLE TR</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Co-operative</td>\n",
              "      <td>1</td>\n",
              "      <td>1-9999</td>\n",
              "      <td>N</td>\n",
              "      <td>108590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>10547893</td>\n",
              "      <td>ST CLOUD PROFESSIONAL FIREFIGHTERS</td>\n",
              "      <td>T5</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C3000</td>\n",
              "      <td>ProductDev</td>\n",
              "      <td>Association</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>N</td>\n",
              "      <td>5000</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>10553066</td>\n",
              "      <td>SOUTHSIDE ATHLETIC ASSOCIATION</td>\n",
              "      <td>T3</td>\n",
              "      <td>CompanySponsored</td>\n",
              "      <td>C2000</td>\n",
              "      <td>Preservation</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>10000-24999</td>\n",
              "      <td>N</td>\n",
              "      <td>6692</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>10556103</td>\n",
              "      <td>GENETIC RESEARCH INSTITUTE OF THE DESERT</td>\n",
              "      <td>T3</td>\n",
              "      <td>Independent</td>\n",
              "      <td>C1000</td>\n",
              "      <td>Heathcare</td>\n",
              "      <td>Trust</td>\n",
              "      <td>1</td>\n",
              "      <td>100000-499999</td>\n",
              "      <td>N</td>\n",
              "      <td>142590</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "        EIN                                      NAME APPLICATION_TYPE  \\\n",
              "0  10520599              BLUE KNIGHTS MOTORCYCLE CLUB              T10   \n",
              "1  10531628    AMERICAN CHESAPEAKE CLUB CHARITABLE TR               T3   \n",
              "2  10547893        ST CLOUD PROFESSIONAL FIREFIGHTERS               T5   \n",
              "3  10553066            SOUTHSIDE ATHLETIC ASSOCIATION               T3   \n",
              "4  10556103  GENETIC RESEARCH INSTITUTE OF THE DESERT               T3   \n",
              "\n",
              "        AFFILIATION CLASSIFICATION      USE_CASE  ORGANIZATION  STATUS  \\\n",
              "0       Independent          C1000    ProductDev   Association       1   \n",
              "1       Independent          C2000  Preservation  Co-operative       1   \n",
              "2  CompanySponsored          C3000    ProductDev   Association       1   \n",
              "3  CompanySponsored          C2000  Preservation         Trust       1   \n",
              "4       Independent          C1000     Heathcare         Trust       1   \n",
              "\n",
              "      INCOME_AMT SPECIAL_CONSIDERATIONS  ASK_AMT  IS_SUCCESSFUL  \n",
              "0              0                      N     5000              1  \n",
              "1         1-9999                      N   108590              1  \n",
              "2              0                      N     5000              0  \n",
              "3    10000-24999                      N     6692              1  \n",
              "4  100000-499999                      N   142590              1  "
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Import our dependencies\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import seaborn as sns\n",
        "\n",
        "\n",
        "#  Import and read the charity_data.csv.\n",
        "import pandas as pd\n",
        "application_df = pd.read_csv(\"https://static.bc-edx.com/data/dl-1-2/m21/lms/starter/charity_data.csv\")\n",
        "application_df.head()\n",
        "print(application_df.info())\n",
        "application_df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2UR9R4fE2P_t"
      },
      "source": [
        "\n",
        "\n",
        "## Data Cleaning\n",
        "\n",
        "### Dropping Non-Beneficial Columns\n",
        "\n",
        "For our analysis, certain columns such as 'EIN' and 'NAME' are not beneficial. These columns serve as identification for the organizations but do not offer any substantive information for our machine learning model. Therefore, we'll drop these columns from our dataset:\n",
        "\n",
        "```python\n",
        "application_df.drop(columns=[\"EIN\", \"NAME\"], inplace=True)\n",
        "```\n",
        "\n",
        "**Note**: It's essential to include the `inplace=True` parameter if you wish to modify the `application_df` directly. Without it, the changes won't be saved to the `application_df` but will return a new DataFrame with the columns dropped.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bZUVs91B2Bpg",
        "outputId": "cfcce003-e8ff-48d0-b490-6cbb80f691aa"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "         ...  \n",
              "C4120        1\n",
              "C8210        1\n",
              "C2561        1\n",
              "C4500        1\n",
              "C2150        1\n",
              "Name: CLASSIFICATION, Length: 71, dtype: int64"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dff = application_df[\"CLASSIFICATION\"].value_counts()\n",
        "dff"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P6w_BmF_2P_t",
        "outputId": "93cf1199-41c6-467b-ba90-3e2de24068ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1    18261\n",
              "0    16038\n",
              "Name: IS_SUCCESSFUL, dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Drop the non-beneficial ID columns, 'EIN' and 'NAME'.\n",
        "application_df.drop(columns=[\"EIN\"] , inplace= True)\n",
        "\n",
        "#check data\n",
        "application_df.head()\n",
        "\n",
        "#check target: to see if there are any bug difrenceses in value count\n",
        "application_df[\"IS_SUCCESSFUL\"].value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kYwF8l232P_u"
      },
      "source": [
        "\n",
        "## Unique Value Analysis\n",
        "\n",
        "To understand the diversity of our dataset and to ascertain potential candidates for one-hot encoding (among other preprocessing steps), we first determine the number of unique values in each column:\n",
        "\n",
        "```python\n",
        "application_df.nunique()\n",
        "```\n",
        "\n",
        "By examining the unique count, we can get insights into the categorical nature of our data and decide on the next preprocessing steps.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iFE2tUAr7F2W",
        "outputId": "acf08054-aaf7-4863-bc45-c3811df0f9ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NAME                      object\n",
              "APPLICATION_TYPE          object\n",
              "AFFILIATION               object\n",
              "CLASSIFICATION            object\n",
              "USE_CASE                  object\n",
              "ORGANIZATION              object\n",
              "STATUS                     int64\n",
              "INCOME_AMT                object\n",
              "SPECIAL_CONSIDERATIONS    object\n",
              "ASK_AMT                    int64\n",
              "IS_SUCCESSFUL              int64\n",
              "dtype: object"
            ]
          },
          "execution_count": 4,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "application_df.dtypes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zPPtXa_t2P_u",
        "outputId": "ad9ff979-bb60-4a56-e8d8-afe7c4a4efe7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "NAME                      19568\n",
              "APPLICATION_TYPE             17\n",
              "AFFILIATION                   6\n",
              "CLASSIFICATION               71\n",
              "USE_CASE                      5\n",
              "ORGANIZATION                  4\n",
              "STATUS                        2\n",
              "INCOME_AMT                    9\n",
              "SPECIAL_CONSIDERATIONS        2\n",
              "ASK_AMT                    8747\n",
              "IS_SUCCESSFUL                 2\n",
              "dtype: int64"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Determine the number of unique values in each column.\n",
        "application_df_count = application_df.nunique()\n",
        "application_df_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uD-H0gDU2P_v",
        "outputId": "0501ce95-18ca-4ea4-d17b-72074bd82525"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T3     27037\n",
              "T4      1542\n",
              "T6      1216\n",
              "T5      1173\n",
              "T19     1065\n",
              "T8       737\n",
              "T7       725\n",
              "T10      528\n",
              "T9       156\n",
              "T13       66\n",
              "T12       27\n",
              "T2        16\n",
              "T25        3\n",
              "T14        3\n",
              "T29        2\n",
              "T15        2\n",
              "T17        1\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Look at APPLICATION_TYPE value counts for binning\n",
        "application_type_count =  application_df[\"APPLICATION_TYPE\"].value_counts()\n",
        "application_type_count"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dr1R8MlO2P_v"
      },
      "source": [
        "\n",
        "\n",
        "1. **Choosing a Cutoff**:\n",
        "    ```python\n",
        "    application_types_to_replace = application_type_count[8:].index\n",
        "    ```\n",
        "   Here, the code selects a cutoff based on the index. The `[8:]` slice means you're taking all application types from the 8th index onward. This assumes that `application_type_count` is already sorted in descending order by count. The code is effectively saying, \"Let's replace all application types from the 8th least frequent type and beyond.\"\n",
        "\n",
        "2. **Replacement**:\n",
        "    ```python\n",
        "    for app in application_types_to_replace:\n",
        "        application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "    ```\n",
        "    This loop replaces all the application types in the `application_types_to_replace` list with the label \"Other\" in the DataFrame `application_df`.\n",
        "\n",
        "3. **Checking**:\n",
        "    ```python\n",
        "    application_df['APPLICATION_TYPE'].value_counts()\n",
        "    ```\n",
        "    This line checks and displays the updated counts for each `APPLICATION_TYPE`, verifying that the replacement was successful.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YR2D4vPN2P_w"
      },
      "source": [
        "---\n",
        "\n",
        "### Explanation\n",
        "\n",
        "---\n",
        "\n",
        "## **Minimizing Application Types**\n",
        "\n",
        "In our dataset, there are multiple `APPLICATION_TYPE`s, some of which occur very infrequently. Having many infrequent categories can sometimes introduce noise into our machine learning models, making them less effective. By reducing the number of infrequent categories, we aim to create a more generalizable model.\n",
        "\n",
        "### **Procedure**:\n",
        "\n",
        "1. **Determine Cutoff**:\n",
        "   \n",
        "   We choose a cutoff to determine which application types are considered \"infrequent.\" For our current approach, we select all application types from the 8th least frequent type onward. These types will be replaced with a more general label: \"Other.\"\n",
        "\n",
        "    ```python\n",
        "    application_types_to_replace = application_type_count[8:].index\n",
        "    ```\n",
        "\n",
        "2. **Replacement**:\n",
        "   \n",
        "   Next, we iterate over the identified application types and replace them in our dataset.\n",
        "\n",
        "    ```python\n",
        "    for app in application_types_to_replace:\n",
        "        application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "    ```\n",
        "\n",
        "3. **Validation**:\n",
        "   \n",
        "   Finally, to ensure our changes have taken effect, we check the updated value counts for `APPLICATION_TYPE`.\n",
        "\n",
        "    ```python\n",
        "    application_df['APPLICATION_TYPE'].value_counts()\n",
        "    ```\n",
        "\n",
        "### **Rationale**:\n",
        "\n",
        "Minimizing the number of categories in our dataset can:\n",
        "\n",
        "- **Enhance Model Generalization**: By reducing sparse categories, we reduce the chance of overfitting to specific categories that don't have enough representation.\n",
        "  \n",
        "- **Streamline Encoding**: Later, when we encode these categories for modeling, fewer categories can lead to fewer columns, making our dataset more manageable and the model faster.\n",
        "\n",
        "- **Improve Interpretability**: Models become more interpretable with fewer categories as the focus shifts to more significant, broad categories rather than nuanced, infrequent ones.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6hregHut2P_w",
        "outputId": "90c5ddaf-0528-479a-fd4f-987474d1ad80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "T3       27037\n",
              "T4        1542\n",
              "T6        1216\n",
              "T5        1173\n",
              "T19       1065\n",
              "T8         737\n",
              "T7         725\n",
              "T10        528\n",
              "Other      276\n",
              "Name: APPLICATION_TYPE, dtype: int64"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of application types to be replaced\n",
        "# use the variable name `application_types_to_replace`\n",
        "application_types_to_replace = [application_type_count[application_type_count.values < 500].index]\n",
        "application_types_to_replace\n",
        "#review video\n",
        "\n",
        "\n",
        "# Replace in dataframe\n",
        "for app in application_types_to_replace:\n",
        "    application_df['APPLICATION_TYPE'] = application_df['APPLICATION_TYPE'].replace(app,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['APPLICATION_TYPE'].value_counts()\n",
        "# application_types_to_replace\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "2nPm9jq92P_w"
      },
      "outputs": [],
      "source": [
        "# Look at CLASSIFICATION value counts for binning\n",
        "classification_count = application_df[\"CLASSIFICATION\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "ZsZCd-BB2P_w"
      },
      "outputs": [],
      "source": [
        "# You may find it helpful to look at CLASSIFICATION value counts >1\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vHM-2JeL4omq"
      },
      "source": [
        "\n",
        "## **Minimizing Classifications**\n",
        "\n",
        "To reduce complexity in the dataset and possibly improve the model's performance, classifications that occur infrequently are grouped together under a single \"Other\" category.\n",
        "\n",
        "### **Procedure**:\n",
        "\n",
        "1. **Determine Classifications to Replace**:\n",
        "    - Choose classifications that occur less than 100 times.\n",
        "    ```python\n",
        "    classification_to_replace = classification_count[classification_count.values < 100].index\n",
        "    ```\n",
        "\n",
        "2. **Replace in DataFrame**:\n",
        "    - Replace the identified classifications in the `CLASSIFICATION` column with \"Other.\"\n",
        "    ```python\n",
        "    for cls in classification_to_replace:\n",
        "        application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "    ```\n",
        "\n",
        "3. **Validate the Replacement**:\n",
        "    - Verify the changes by checking the updated value counts.\n",
        "    ```python\n",
        "    application_df['CLASSIFICATION'].value_counts()\n",
        "    ```\n",
        "\n",
        "### **Benefits**:\n",
        "\n",
        "- **Model Simplicity**: By reducing sparse categories, the model might be less prone to overfitting.\n",
        "- **Interpretability**: Grouping infrequent classifications into a broader category simplifies interpretation.\n",
        "- **Computational Efficiency**: Fewer unique values might lead to a more efficient encoding process later in the data preprocessing pipeline.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PazBY-B32P_x",
        "outputId": "8306c877-e780-41fd-e526-f96ddd7b8f2d"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "C1000    17326\n",
              "C2000     6074\n",
              "C1200     4837\n",
              "C3000     1918\n",
              "C2100     1883\n",
              "C7000      777\n",
              "Other      669\n",
              "C1700      287\n",
              "C4000      194\n",
              "C5000      116\n",
              "C1270      114\n",
              "C2700      104\n",
              "Name: CLASSIFICATION, dtype: int64"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Choose a cutoff value and create a list of classifications to be replaced\n",
        "# use the variable name `classifications_to_replace`\n",
        "classification_to_replace = classification_count[classification_count.values < 100 ].index\n",
        "classification_to_replace\n",
        "# Replace in dataframe\n",
        "for cls in classification_to_replace:\n",
        "    application_df['CLASSIFICATION'] = application_df['CLASSIFICATION'].replace(cls,\"Other\")\n",
        "\n",
        "# Check to make sure binning was successful\n",
        "application_df['CLASSIFICATION'].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "PARENT BOOSTER USA INC                                                  1260\n",
              "TOPS CLUB INC                                                            765\n",
              "UNITED STATES BOWLING CONGRESS INC                                       700\n",
              "WASHINGTON STATE UNIVERSITY                                              492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC                          408\n",
              "                                                                        ... \n",
              "ST LOUIS SLAM WOMENS FOOTBALL                                              1\n",
              "AIESEC ALUMNI IBEROAMERICA CORP                                            1\n",
              "WEALLBLEEDRED ORG INC                                                      1\n",
              "AMERICAN SOCIETY FOR STANDARDS IN MEDIUMSHIP & PSYCHICAL INVESTIGATI       1\n",
              "WATERHOUSE CHARITABLE TR                                                   1\n",
              "Name: NAME, Length: 19568, dtype: int64"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names_count = application_df[\"NAME\"].value_counts()\n",
        "names_count\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0gXGButH9TGc",
        "outputId": "0accfd58-b6aa-49a2-af43-71835c369955"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Other                                                28539\n",
              "PARENT BOOSTER USA INC                                1260\n",
              "TOPS CLUB INC                                          765\n",
              "UNITED STATES BOWLING CONGRESS INC                     700\n",
              "WASHINGTON STATE UNIVERSITY                            492\n",
              "AMATEUR ATHLETIC UNION OF THE UNITED STATES INC        408\n",
              "PTA TEXAS CONGRESS                                     368\n",
              "SOROPTIMIST INTERNATIONAL OF THE AMERICAS INC          331\n",
              "ALPHA PHI SIGMA                                        313\n",
              "TOASTMASTERS INTERNATIONAL                             293\n",
              "MOST WORSHIPFUL STRINGER FREE AND ACCEPTED MASONS      287\n",
              "LITTLE LEAGUE BASEBALL INC                             277\n",
              "INTERNATIONAL ASSOCIATION OF LIONS CLUBS               266\n",
              "Name: NAME, dtype: int64"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "names_count = application_df[\"NAME\"].value_counts()\n",
        "names_to_replace = names_count[names_count < 250].index\n",
        "\n",
        "for name in names_to_replace:\n",
        "    application_df['NAME'] = application_df['NAME'].replace(name, \"Other\")\n",
        "\n",
        "application_df[\"NAME\"].value_counts()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hWzRB7SE5kGb"
      },
      "source": [
        "# **get_dummies**\n",
        "### Code:\n",
        "\n",
        "```python\n",
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df)\n",
        "```\n",
        "\n",
        "### Explanation:\n",
        "\n",
        "- **What It Does**: The `pd.get_dummies()` function converts categorical variables into a \"dummy\" or \"indicator\" matrix. For each unique value in the categorical column, it creates a new binary column, where the value is 1 if the original column's value matches that unique value and 0 otherwise.\n",
        "- **Why It's Used**: Many machine learning algorithms require numerical input, so categorical variables must be transformed into a numerical format. By creating these \"dummy\" binary columns, the information in the categorical variables is preserved in a way that can be utilized by algorithms.\n",
        "\n",
        "### Example:\n",
        "\n",
        "Suppose you have a column named \"color\" with values \"red,\" \"blue,\" and \"green.\" After applying `pd.get_dummies()`, you'll have three new columns: \"color_red,\" \"color_blue,\" and \"color_green.\" Each row will have a 1 in the column corresponding to its color and 0s in the other two.\n",
        "\n",
        "\n",
        "## **Converting Categorical Data to Numeric Form**\n",
        "\n",
        "### **Objective**:\n",
        "\n",
        "Transform categorical variables into numerical format, allowing them to be processed by machine learning algorithms.\n",
        "\n",
        "### **Procedure**:\n",
        "\n",
        "1. **Use the `pd.get_dummies` Method**:\n",
        "    - Apply the `pd.get_dummies()` function to the entire DataFrame to convert all categorical columns into dummy variables.\n",
        "    ```python\n",
        "    application_df = pd.get_dummies(application_df)\n",
        "    ```\n",
        "\n",
        "### **Result**:\n",
        "\n",
        "- The categorical variables in the dataset have been replaced with binary dummy variables.\n",
        "- Each unique value in the original categorical columns has been converted into a separate column, with binary values indicating the presence or absence of that category in each observation.\n",
        "\n",
        "### **Benefits**:\n",
        "\n",
        "- **Compatibility with Algorithms**: This transformation ensures that the data can be used with algorithms that require numerical input.\n",
        "- **Preservation of Information**: The categorical information is preserved in a numerical format that retains the distinctions between different categories.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "KJU8WflNnSwU",
        "outputId": "5bbd77d6-51bd-408d-811c-5697aaff9b49"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "1soqfm0k2P_x"
      },
      "outputs": [],
      "source": [
        "# Convert categorical data to numeric with `pd.get_dummies`\n",
        "application_df = pd.get_dummies(application_df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "4JhHMx_Q2P_x"
      },
      "outputs": [],
      "source": [
        "# Split our preprocessed data into our features and target arrays\n",
        "y = application_df[\"IS_SUCCESSFUL\"].values\n",
        "X = application_df.drop(columns=\"IS_SUCCESSFUL\").values\n",
        "\n",
        "# Split the preprocessed data into a training and testing dataset\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=78)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "7yNViUGL2P_x"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "62"
            ]
          },
          "execution_count": 15,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create a StandardScaler instances\n",
        "scaler = StandardScaler()\n",
        "\n",
        "# Fit the StandardScaler\n",
        "X_scaler = scaler.fit(X_train)\n",
        "\n",
        "# Scale the data\n",
        "X_train_scaled = X_scaler.transform(X_train)\n",
        "X_test_scaled = X_scaler.transform(X_test)\n",
        "\n",
        "X_train_scaled.shape[1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d-vXXQAP2P_x"
      },
      "source": [
        "## Compile, Train and Evaluate the Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "\n",
        "## Defining the Deep Neural Network Model\n",
        "\n",
        "We're defining a deep neural network with three layers: two hidden layers and an output layer. The structure of the network is as follows:\n",
        "\n",
        "### Input Dimension\n",
        "\n",
        "The number of input features is defined as the length of the first record in our training set (`X_train[0]`), and it is stored in the variable `number_input_features`.\n",
        "\n",
        "### Hidden Layers\n",
        "\n",
        "- **First Hidden Layer:** This layer contains `1.5 * number_input_features` neurons and uses the ReLU (Rectified Linear Unit) activation function.\n",
        "- **Second Hidden Layer:** This layer contains `1 * number_input_features` neurons and also uses the ReLU activation function.\n",
        "\n",
        "### Output Layer\n",
        "\n",
        "The output layer consists of a single neuron, as this is a binary classification task. It uses the sigmoid activation function to output a probability that the input belongs to the positive class.\n",
        "\n",
        "### Model Summary\n",
        "\n",
        "After defining the architecture, we call the `nn.summary()` method to display a summary of the model's structure.\n",
        "\n",
        "\n",
        "This architecture is flexible and can be adjusted by changing the number of hidden layers, the number of neurons in each layer, or the activation functions used."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "NYTXH4HF7uqJ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_3 (Dense)             (None, 93)                5859      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 62)                5828      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 1)                 63        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 11,750\n",
            "Trainable params: 11,750\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        " # Define the model - deep neural net\n",
        "number_input_features = len(X_train[0])\n",
        "hidden_nodes_layer1 =  1.5 * number_input_features\n",
        "hidden_nodes_layer2 = 1 * number_input_features\n",
        "\n",
        "nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=hidden_nodes_layer1,\n",
        "        input_dim=number_input_features,\n",
        "        activation=\"relu\")\n",
        ")\n",
        "\n",
        "# Second hidden layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=hidden_nodes_layer2,\n",
        "        activation=\"relu\"))\n",
        "\n",
        "# Output layer\n",
        "nn.add(\n",
        "    tf.keras.layers.Dense(\n",
        "        units=1,\n",
        "        activation=\"sigmoid\"))\n",
        "\n",
        "# Check the structure of the model\n",
        "nn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "4EDgdxa02P_y"
      },
      "outputs": [],
      "source": [
        "# Define the model - deep neural net, i.e., the number of input features and hidden nodes for each layer.\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# nn = tf.keras.models.Sequential()\n",
        "\n",
        "# First hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# Second hidden layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# Output layer\n",
        "#  YOUR CODE GOES HERE\n",
        "\n",
        "# # Check the structure of the model\n",
        "# nn.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Compiling the Model\n",
        "\n",
        "### Overview\n",
        "\n",
        "The compilation step is where the learning process is configured before training the model. It includes specifying the loss function, the optimizer, and the evaluation metrics.\n",
        "\n",
        "### Components\n",
        "\n",
        "#### Loss Function\n",
        "- **binary_crossentropy**: Suitable for binary classification problems, this loss function computes the cross-entropy loss between true labels and predicted labels.\n",
        "\n",
        "#### Optimizer\n",
        "- **adam**: An efficient and effective optimizer, commonly used in deep learning.\n",
        "\n",
        "#### Metrics\n",
        "- **accuracy**: Measures the proportion of correctly classified instances.\n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
        "```\n",
        "\n",
        "### Summary\n",
        "\n",
        "This compilation sets the stage for training the neural network. By specifying the loss function, optimizer, and metrics, the model is prepared to learn from the training data and evaluate its performance on both training and testing datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "Qw4VfwAk2P_y"
      },
      "outputs": [],
      "source": [
        "# Compile the model\n",
        "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Training the Model\n",
        "\n",
        "### Overview\n",
        "\n",
        "Once the model has been defined and compiled, the next step is to train it on the data. Training involves feeding the input data into the model, letting it make predictions, and then updating the model's weights based on the error of its predictions. This process is repeated for a specified number of iterations, known as epochs.\n",
        "\n",
        "### Components\n",
        "\n",
        "#### Training Data\n",
        "- **X_train_scaled**: The scaled input features for training the model.\n",
        "- **y_train**: The true labels corresponding to the input features.\n",
        "\n",
        "#### Epochs\n",
        "- **epochs**: This argument specifies the number of times the learning algorithm will work through the entire training dataset. In this case, 100 epochs are chosen.\n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled, y_train, epochs=100)\n",
        "```\n",
        "\n",
        "### Summary\n",
        "\n",
        "This code snippet is where the actual training of the neural network takes place. By calling the `fit` method on the model (`nn`) and providing the training data, the model will iteratively learn from the data 100 times. The results of this training (including information on loss and accuracy for each epoch) are stored in the variable `fit_model`, which can be further analyzed or used to make predictions on unseen data.\n",
        "\n",
        "Note: The number of epochs is a hyperparameter that can be tuned. Choosing the right number of epochs is vital as too few may result in underfitting, while too many may lead to overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sXqvqJQS2P_y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "  1/804 [..............................] - ETA: 14s - loss: 0.4800 - accuracy: 0.6875"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4888 - accuracy: 0.7619\n",
            "Epoch 2/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4882 - accuracy: 0.7615\n",
            "Epoch 3/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4878 - accuracy: 0.7621\n",
            "Epoch 4/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4880 - accuracy: 0.7629\n",
            "Epoch 5/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4885 - accuracy: 0.7617\n",
            "Epoch 6/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4879 - accuracy: 0.7628\n",
            "Epoch 7/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4876 - accuracy: 0.7626\n",
            "Epoch 8/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4878 - accuracy: 0.7623\n",
            "Epoch 9/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4881 - accuracy: 0.7619\n",
            "Epoch 10/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4877 - accuracy: 0.7623\n",
            "Epoch 11/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4872 - accuracy: 0.7621\n",
            "Epoch 12/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4875 - accuracy: 0.7615\n",
            "Epoch 13/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.7633\n",
            "Epoch 14/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4877 - accuracy: 0.7633\n",
            "Epoch 15/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4870 - accuracy: 0.7624\n",
            "Epoch 16/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7625\n",
            "Epoch 17/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4865 - accuracy: 0.7633\n",
            "Epoch 18/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4871 - accuracy: 0.7630\n",
            "Epoch 19/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7621\n",
            "Epoch 20/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.7629\n",
            "Epoch 21/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4869 - accuracy: 0.7636\n",
            "Epoch 22/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4867 - accuracy: 0.7629\n",
            "Epoch 23/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4868 - accuracy: 0.7626\n",
            "Epoch 24/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4862 - accuracy: 0.7630\n",
            "Epoch 25/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4870 - accuracy: 0.7622\n",
            "Epoch 26/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4863 - accuracy: 0.7633\n",
            "Epoch 27/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7622\n",
            "Epoch 28/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.7630\n",
            "Epoch 29/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7629\n",
            "Epoch 30/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4858 - accuracy: 0.7626\n",
            "Epoch 31/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4859 - accuracy: 0.7631\n",
            "Epoch 32/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4863 - accuracy: 0.7633\n",
            "Epoch 33/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4859 - accuracy: 0.7631\n",
            "Epoch 34/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4861 - accuracy: 0.7627\n",
            "Epoch 35/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.7633\n",
            "Epoch 36/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4859 - accuracy: 0.7638\n",
            "Epoch 37/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4860 - accuracy: 0.7635\n",
            "Epoch 38/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4867 - accuracy: 0.7627\n",
            "Epoch 39/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7633\n",
            "Epoch 40/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4856 - accuracy: 0.7636\n",
            "Epoch 41/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4860 - accuracy: 0.7634\n",
            "Epoch 42/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4853 - accuracy: 0.7636\n",
            "Epoch 43/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4858 - accuracy: 0.7640\n",
            "Epoch 44/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4855 - accuracy: 0.7625\n",
            "Epoch 45/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4855 - accuracy: 0.7636\n",
            "Epoch 46/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4862 - accuracy: 0.7626\n",
            "Epoch 47/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7630\n",
            "Epoch 48/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4853 - accuracy: 0.7636\n",
            "Epoch 49/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4854 - accuracy: 0.7622\n",
            "Epoch 50/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7637\n",
            "Epoch 51/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7634\n",
            "Epoch 52/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4848 - accuracy: 0.7635\n",
            "Epoch 53/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4854 - accuracy: 0.7641\n",
            "Epoch 54/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7626\n",
            "Epoch 55/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7636\n",
            "Epoch 56/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4855 - accuracy: 0.7627\n",
            "Epoch 57/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4848 - accuracy: 0.7639\n",
            "Epoch 58/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4851 - accuracy: 0.7636\n",
            "Epoch 59/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4850 - accuracy: 0.7636\n",
            "Epoch 60/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4846 - accuracy: 0.7631\n",
            "Epoch 61/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7638\n",
            "Epoch 62/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4854 - accuracy: 0.7634\n",
            "Epoch 63/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4847 - accuracy: 0.7634\n",
            "Epoch 64/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.7641\n",
            "Epoch 65/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4850 - accuracy: 0.7638\n",
            "Epoch 66/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4846 - accuracy: 0.7639\n",
            "Epoch 67/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4847 - accuracy: 0.7633\n",
            "Epoch 68/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4841 - accuracy: 0.7634\n",
            "Epoch 69/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4850 - accuracy: 0.7637\n",
            "Epoch 70/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4853 - accuracy: 0.7629\n",
            "Epoch 71/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4845 - accuracy: 0.7638\n",
            "Epoch 72/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4840 - accuracy: 0.7642\n",
            "Epoch 73/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4845 - accuracy: 0.7632\n",
            "Epoch 74/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4843 - accuracy: 0.7643\n",
            "Epoch 75/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4848 - accuracy: 0.7639\n",
            "Epoch 76/100\n",
            "804/804 [==============================] - 2s 3ms/step - loss: 0.4844 - accuracy: 0.7640\n",
            "Epoch 77/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7637\n",
            "Epoch 78/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4839 - accuracy: 0.7635\n",
            "Epoch 79/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4844 - accuracy: 0.7636\n",
            "Epoch 80/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4839 - accuracy: 0.7640\n",
            "Epoch 81/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7641\n",
            "Epoch 82/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7638\n",
            "Epoch 83/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7637\n",
            "Epoch 84/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4842 - accuracy: 0.7635\n",
            "Epoch 85/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4843 - accuracy: 0.7640\n",
            "Epoch 86/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4844 - accuracy: 0.7638\n",
            "Epoch 87/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4840 - accuracy: 0.7636\n",
            "Epoch 88/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4848 - accuracy: 0.7634\n",
            "Epoch 89/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4841 - accuracy: 0.7636\n",
            "Epoch 90/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4838 - accuracy: 0.7645\n",
            "Epoch 91/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4851 - accuracy: 0.7640\n",
            "Epoch 92/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4846 - accuracy: 0.7634\n",
            "Epoch 93/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4839 - accuracy: 0.7635\n",
            "Epoch 94/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4840 - accuracy: 0.7642\n",
            "Epoch 95/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4836 - accuracy: 0.7635\n",
            "Epoch 96/100\n",
            "804/804 [==============================] - 1s 2ms/step - loss: 0.4834 - accuracy: 0.7641\n",
            "Epoch 97/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4844 - accuracy: 0.7633\n",
            "Epoch 98/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4834 - accuracy: 0.7636\n",
            "Epoch 99/100\n",
            "804/804 [==============================] - 2s 2ms/step - loss: 0.4838 - accuracy: 0.7631\n",
            "Epoch 100/100\n",
            "804/804 [==============================] - 1s 1ms/step - loss: 0.4838 - accuracy: 0.7631\n"
          ]
        }
      ],
      "source": [
        "# Train the model\n",
        "fit_model = nn.fit(X_train_scaled,y_train,epochs=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Evaluating the Model\n",
        "\n",
        "### Overview\n",
        "\n",
        "After training the neural network model, it is important to evaluate how well the model performs on unseen data. This is usually done by running the model on a test dataset and comparing the predictions to the actual values.\n",
        "\n",
        "### Components\n",
        "\n",
        "#### Test Data\n",
        "- **X_test_scaled**: The scaled input features for the test data.\n",
        "- **y_test**: The true labels corresponding to the test data.\n",
        "\n",
        "#### Evaluation Method\n",
        "- `nn.evaluate()`: This method takes the test data as input and computes the loss and any additional metrics specified when the model was compiled (in this case, accuracy). \n",
        "\n",
        "### Code\n",
        "\n",
        "```python\n",
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled, y_test, verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")\n",
        "```\n",
        "\n",
        "### Summary\n",
        "\n",
        "The code snippet above is used to evaluate the trained model on the test dataset. The `evaluate` method returns the loss and accuracy, which are printed to the console.\n",
        "\n",
        "- **Loss**: This value represents how well the predictions of the model align with the actual values. A lower loss indicates better alignment.\n",
        "- **Accuracy**: This value represents the percentage of correct predictions made by the model out of all predictions. It is particularly useful for classification problems.\n",
        "\n",
        "By evaluating the model on a dataset that it has not seen during training, we can get a better sense of how the model might perform on entirely new data. This helps in assessing the model's generalization capability."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "A5fmFwh22P_y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "268/268 - 0s - loss: 0.5272 - accuracy: 0.7459 - 413ms/epoch - 2ms/step\n",
            "Loss: 0.5272284150123596, Accuracy: 0.7458891868591309\n"
          ]
        }
      ],
      "source": [
        "# Evaluate the model using the test data\n",
        "model_loss, model_accuracy = nn.evaluate(X_test_scaled,y_test,verbose=2)\n",
        "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "0G9V__Vq2P_y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model saved to disk.\n"
          ]
        }
      ],
      "source": [
        "# Export our model to HDF5 file\n",
        "# Save the model to disk\n",
        "nn.save(\"AlphabetSoupCharity_Optimization.h5\")\n",
        "print(\"Model saved to disk.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.9"
    },
    "vscode": {
      "interpreter": {
        "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
